# 系统架构设计师

## 1 计算机组成与体系结构

### 1.1 计算机系统组成

#### 1.1.1 计算机硬件组成

硬件是设备实体，冯诺伊曼计算机结构上以**运算器**为中心，现在转向**存储器**为核心

- 控制器(主机->CPU)：统一控制指挥并控制计算机各部件协调工作的中心部件
  - 程序计算器PC：存储下一条执行指令的地址
  - 指令寄存器IR：存储即将执行的指令
  - 指令译码器ID：对指令中的操作码字段进行分析解释
  - 时序部件：时序控制信号
- 运算器(主机->CPU)：ALU，在控制器控制下完成算术运算和逻辑运算。
  - 算数逻辑单元ALU：数据的算数运算和逻辑运算。
  - 累加寄存器AC：为ALU提供工作区暂存数据
  - 数据缓冲寄存器DR：写内存时暂存指令或数据
  - 状态条件寄存器PSW：存状态标志与控制标识(争议：也可归于控制器)
- 主存储器(主机)：存储现场操作的信息和中间结果，包括机器指令和数据
- 辅助存储器(外设)：外存/辅存。存储需要长期保存的各种信息
- 输入设备
- 输出设备

#### 1.1.2 计算机系统结构的分类

电子管->晶体管->集成电路（中小规模，大规模，超大规模，甚大规模，极大规模）

世界上最高水平的单片集成电路芯片上容纳的元器件已经达到**80多亿**个。

1）存储程序的概念：冯诺伊曼1946.6提出。

- 计算机（硬件）应由运算器、存储器、控制器、输入和输出设备这五个基本部件组成
- 计算机内部使用二进制来表示指令和数据
- 将程序和原始数据存入存储器中，然后启动计算机工作。这就是存储程序的基本含义

**存储程序控制**概念的提出和实现时冯诺伊曼对计算机界的最大贡献。这种计算机叫做冯诺伊曼计算机。但存在存储器访问的瓶颈。对于突破这种瓶颈的计算机叫做非冯诺伊曼型计算机（数据驱动的数据流计算机，需求驱动的规约计算机，模式匹配驱动的智能计算机）

2）Flynn分类

根据指令流，数据流的多倍性特征分类。

- 指令流：机器执行的指令序列
- 数据流：指令流调用的数据序列。包括输入数据和中间结果。不包括输出数据。

2*2，将计算机系统分成4类

- 单指令流单数据流；SISD，传统顺序执行的单处理器计算机。其指令部件每次只对一条指令进行译码，只对一个操作部件分配数据
- 单指令流多数据流：SIMD，以并行处理机（矩阵处理机）为代表，并行处理机包括多个重复的处理单元，由单一指令部件控制，按照统一指令流的要求为他们分配各自不同所需的不同数据
- 多指令流单数据流：MISD，具有N个处理单位，按N条不同指令的要求对同一数据流及其中间结果进行不同的处理。一个处理单元的输出又作为另一个处理单元的输入。这类系统较少，可参照流水线理解，也有文献称流水线计算机是MIMD
- 多指令流多数据流：MIMD，能实现作业、任务、指令等各级全面并行的多机系统。如多核处理器，多处理机属于MIMD

#### 1.1.3 复杂指令集系统和精简指令集系统

指令优化设计又两个截然相反的方向

- 增强指令的功能，设置一些功能复杂的指令，把一些原来由软件实现的常用的功能改用指令系统来实现（仿佛是造轮子？）。这种计算机系统被称为复杂指令系统计算机（CISC）
  - 指令数量众多，通常有100-250条
  - 使用频率相差悬殊，最长使用简单的指令仅占指令总数的20%出现了80%，大部分复杂指令很少使用（典型的二八原则啊）
  - 支持很多寻址方式，支持的通常为5-20种
  - 变长的指令，指令长度不规定。增加指令译码电路的复杂性
  - 指令可以对主存单元的数据直接进行处理。执行速度较慢
  - 微程序控制为主。CISC指令系统复杂，很难用硬布线逻辑（组合逻辑）电路实现控制器，通常使用微程序控制。
- 尽量简化指令功能，只保留那些功能简单，能在一个节拍内执行完成指令，复杂的功能用一段子程序来实现。这种计算机系统成为精简指令系统计算机（RISC）
  - 指令少，优鲜选取使用频率高的一些简单指令和常用指令。只提供了LOAD（存储器读数）和STORE（数据写入存储器）两条指令对存储器操作，其他都在CPU的寄存器之间进行
  - 寻址方式少。通常只有寄存器寻址，立即数寻址和相对寻址
  - 指令长度固定。译码简单
  - 硬布线逻辑控制为主。为了提供操作的执行速度，通常采用硬布线逻辑来构建控制器
  - 单周期指令执行。采用流水线技术。少数指令可能需要多周期（LOAD/STORE因为要访问存储器，执行的时间会稍微长）
  - 优化的编译器：RISC使编译工作简单化。因为指令长度固定，格式少，寻址方式少，编译时不必在具有相似功能的指令中进行选择，也不必为寻址方式的选择而费心，易于实现优化。
  - CPU种通用寄存器数量多，一般在32以上，甚至可达上千个。大多RISC采用了Cache方案，使用Cache来提供取指令的速度。有的RISC使用两个独立的Cache来改善性能，一个为指令Cache一个时数据Cache，这样取指令和取数据可以同时进行互不干扰。

#### 1.1.4 总线

一组能为多个部件分时（同一时刻只允许一个部件向总线发送消息，允许多个部件同时接受同样信息）共享（总线可以挂接多个部件，各个部件之间相关交换的信息都可以通过这组公共线路传送）的公共信息传送线路。

按总线相对CPU或其他芯片的位置可分为：

- CPU内部，寄存器之间和算数逻辑部件ALU与控制部件之间传输数据的总线为内部总线；
- 外部总线则是CPU与内存RAM，ROM和输入输出设备接口之间通信的通路。**总线速度**是制约计算机整体性能的最大因素。

功能分：

- 地址总线：传送地址信息
- 数据总线：传送数据信息
- 控制总线：传送各种控制信号

### 1.2 存储器系统

#### 1.2.1 主存储器

存放计算机运行期间需要的程序和数据，CPU可随机进行读写。存取速度较高。

根据工艺和技术不同，可分为

- 随机存取存储器：RAM，可写可读，断电后信息无法保存，只能暂存。
  - DRAM：随时间逐渐消失，需要定时对其刷新维持消息不丢失，密度大于SRAM且更加便宜。
  - SRAM：在不断电的情况下信息能够一直保持不会丢失。电路简单，容量小，价格高
- 只读存储器：ROM，**一种RAM的特殊形式**，写入后只能随机读出不能写入。又被称为固定存储器，一般存放系统程序BIOS

内存编址在计算机系统中，存储器每个单元的位数是相同且固定的，称为存储器编址单位

内存一般以字节（8位）为单位，或者以字（会标注大小，16位或者32位）为单位

<u>内存地址H1到H2，则共有H2-H1+1个地址单元，写作H3。如果内存地址按字（16bit）编址，则共有H3*16位，假设内存有X片存储器芯片构成，每片有H4个存储单位，则每个单元存储（H3 * 16）/ （X * H4）位</u>

#### 1.2.2 辅助存储器

- 磁带存储器是一种顺序存取的设备。存取时间较长，存储容量大，便于携带，价格便宜。目前应用场景极少，用于资料的归档保存。
- 硬盘存储器。
  - 磁盘片有m个磁道就有m个柱面。会讲一个文件尽量的存放在同一个柱面种，如果存放不完，再存入相邻的柱面。
  - 通常将一条磁道划分为若干个段，每个段成为一个扇区或者扇段，每个扇区存放一个定长信息块（例如512个字节，由操作系统决定），**扇区从编号1开始，磁头和柱面编号从0开始**
  - 磁盘访问时间（存取时间）=寻道时间+旋转延迟时间

#### 1.2.3 Cache存储器

Cache的功能是提供CPU数据输入输出的速率，突破冯诺伊曼瓶颈（内存速度）。Cache容量小但是速度快，内存速度低但是容量大通过优化调度算法，系统的性能会大大改善。

Cache通常采用相联存储器（CAM）。CAM是一种基于**数据内容**进行访问的存储设备。在写入数据时，CAM能够自动选择一个未用的空单元进行存储；<u>当要读出数据时，不是给出其存储单元的地址，而是直接给出该数据或者该数据的一部分内容</u>，CAM对所有的存储单元中的数据同时进行比较，标记符合条件的所有数据以供读取。由于比较是同时、并行进行的，所以基于数据内容进行读写的机制，速度比基于地址读写方式要快得多。

##### 基本原理

使用Cache改善系统性能的依据是程序的局部性原理。根据程序的局部性原理，最近的、未来要用的指令和数据大多局限于正在用的指令和数据，或者存放在与这些指令和数据位置上临近的单元中。

如果h表示Cache的访问命中率，t1表示cache的周期时间，t2表示内存的周期时间，以读操作为例，使用Cache+主存储器的系统的平均周期为t3，则公式为：t3 = t1*h + t2(1-h)

##### 映射机制

当CPU发出访存请求后，存储器地址先被送到Cache控制器以确定数据是否已在Cache中，若命中则直接对Cache进行访问。这个过程称为Cache的地址映射。在Cache的地址映射中，主存和Cache将均分成容量相同的块（页）。常见有直接映射，全相联映射和组相联映射。

###### 直接映射

以随机存取存储器作为Cache存储器，硬件电路较简单。

设定内存容量为1G，Cache为8MB，页大小为512K。直接映射中，先分区在分页，一区的大小就是Cache的大小，因此一共氛围1G/1M=128， 区号为7位，每个区8M/512K=16，页号为4。

直接映射中，每个内存也只能复制到某一固定的Cache页中。即如果当前时候Cache中0页被占据，而1-15空闲，这时候将1区的0页数据调入Cache是会发生冲突的。因此直接映射的块冲突率很高。

###### 全相联映射

使用相联存储器组成的Cache存储器。在全相联映射中，主存的每一页可以映射到Cache的任一页。

对于直接映射来说，这里使用的页号直接是11位了，没有区号的概念。因此每页的Cache标记也需要11位，以表明它现在所映射的主页号，因此Cache的标记位数增加增加，比较逻辑成本增加。

主存地址不能直接提取Cache页号，需要逐个比对，直到找到标记的页，这种速度很慢，失掉了高速缓存的作用。如果主存页标记与各Cache标记同时比较，成本又太高。全相联映射方式因比较器电路难于设计和实现，只适用于小容量的Cache。

###### 组相联映射

主存中的组与Cache的组形成直接印象关系，组队的页是全相联映射关系，即主存1区0组0页，只能进入Cache的0组中，但是具体是0页还是1页没有强制要求，可以随意放置。即组是一一对应的， 页是需要查询对应的。如果每组只有一页的话，其实等同于直接映射了。如果每组页为16，那就是全相联映射。

为了保障性能，内存和Cache之间的映射一般有硬件完成，因此Cache对程序员是透明的。

##### 替换算法

- 随机
- 先入先出（FIFO）
- 最近最少使用（LRU）

##### 写操作

- 写直达：写Cache时，数据同时写回内存，当一块需要替换时，也不必把这块写回到主存中。可以直接覆盖。实现简单，随时保持主存数据的正确性，但是可能增加不必要的主存写入，降低存取速度
- 写回：CPU修改Cache后数据不like写入内存。当被淘汰的时候才写回到内存中。这种策略的cache块表中，一般由一个标识位，单元被修改时至1，需要替换时如果标识位为1那就需要先写回，如果0，表示这一块不必写入主存，直接覆盖。
- 标记法：对Cache的每个数据设置一个有效位。当数据进入Cache后，有效位置1，当CPU对数据修改时，数据只需写入内存并且置0。当要从Cache读取数据时需要测试其有效位。如果1从Cache获取，否则从内存。

### 1.3 流水线

#### 1.3.1 流水线周期

流水线应用过程中，会将需要处理的工作分为N各阶段，最耗时那一段消耗的时间为流水线周期。如：使用流水线技术执行100条指令，每条指令取指2ms，分析4ms，执行1ms，则周期为4ms

#### 1.3.2 计算流水线执行时间

将1个任务的执行过程分成N个阶段，每个阶段完成时间为t， 则完成该任务的时间为Nt，传统的角度来说，完成k个任务所需要的时间为kNt；使用流水线技术执行，花费的时间是Nt+(k-1)t。除了第一个任务需要完成的时间，其他都可以通过并行执行。

因此 ： 流水线执行时间=第一条指令的执行时间+（n-1）*流水线周期

以1.3.1的例子来说，可明显认为流水线周期为4ms，那么完成100条指令为 2+4+1+（100-1）*4=403ms

特殊：实际上，考虑处理的复杂性，会将每个执行阶段的时间统一为流水线周期，即一条指令为12ms，最后执行结果为4+4+4+4*（100-1）=408ms。

#### 1.3.3 流水线的吞吐率

任务数/处理完成对应任务数所需要用的时间

#### 1.3.4 流水线的加速比

完成同样一批任务，不使用流水线所用的时间与使用流水线所用的时间之比成为流水线的加速比。顺序执行所用时间为t0，使用流水线为t1，则加速比为t0/t1

## 2 操作系统

### 2.1 操作系统的类型与结构

#### 2.1.1 操作系统的定义

计算机系统中的核心系统软件，负责管理和控制计算机系统中的硬件和软件资源，合理的组织计算机工作流程和有效利用资源。在计算机与用户之间起接口的作用。操作系统为用户提供命令菜单窗口等，为应用程序提供API。

#### 2.1.2 操作系统分类

- 批处理操作系统
- 分时操作系统
- 实时操作系统
- 网络操作系统
- 分布式操作系统
- 嵌入式操作系统
- 微内核操作系统

### 2.2 操作系统基本原理

#### 2.2.1 进程管理

**处理机**是计算器系统的核心资源，处理机的充分利用有利于系统效率的大大提高。处理机管理集中了操作系统中最复杂的部分，它设计的好坏关系到整个系统的成败。

**进程**是处理机管理中最基本的最重要的概念。进程是系统并发执行的体现。

> 为了动态的看待操作系统，则以进程作为独立运行的基本单位，以进程作为分配资源的基本单位，从进程的角度来研究操作系统。处理机管理也被称为进程管理。处理机管理的功能就是组织和协调用户对处理机的争夺使用，把处理机分配给进程，对进程进行管理和控制，最大限度也发挥处理机的作用

##### 2.2.1.1 进程的概念

- 静态：操作系统是一组程序和表格的集合。
- 动态：操作系统是进程的动态和并发执行的

> 顺序程序：早期的程序设计，指程序中若干操作必须按照某种先后次序来执行，并且每次操作钱和操作后的数据，状态都有一定的关系。
>

在多道程序系统中，程序的运行环境发生了很大的变化

1. 资源共享。为了提供资源的利用率，计算机系统中的资源不再由一道程序专用，而是由多道程序共同使用。
2. 程序的并发/并行执行。实际上是大多程序段只要求操作在时间上是有序的，也就是A操作必须在B操作之前，这是有序的，但是其中有些操作可以同时进行。
   1. 逻辑上
      1. 允许多道不同用户的程序并行运行
      2. 允许一个用户程序内部完成不同操作的程序段之间并行运行
      3. 允许操作系统内部不同程序之间并行运行
   2. 物理上
      1. 内存储器中保存多个程序，IO设备被多个程序交替的共享使用
      2. 在多处理机系统的情形下，表现为多个程序在各自的处理机上运行，执行时间是重叠的。单处理机系统时，程序的执行表现为多道程序交替地在处理机上互相空插运行。

##### 2.2.1.2 进程的状态转换

由于进程运行的间断性， 决定了进程至少具体以下三种状态，进程的状态可以动态的相互转换，但是阻塞的进程不能直接进入执行状态（阻塞-就绪-执行），就绪不能直接进入阻塞（就绪-执行-阻塞）。**任何时刻任何进程都处于其中一种状态**

- 就绪：当**进程已分配了除CPU以外的所有必要的资源**后，只要能再获得处理机，便能立即执行。一个系统中，可以有多个进程同时就绪，通常称为一个队列，称为就绪队列
- 执行：**进程已获得处理机，程序正在执行**。单处理机系统中，只有一个进程处于执行状态。
- 阻塞：进程因为发生某事件（请求IO，申请缓冲空间）而暂停执行时的状态。进程执行收到阻塞。（或称：等待，睡眠）。通常将处于阻塞状态的进程排成一个队列称为阻塞队列。

转换：

![image-20220716100413769](系统架构设计师.assets/image-20220716100413769.png)

- 运行-阻塞：进程运行中启动了外围设备，就变成了<u>等待外围设备传输信息的状态</u>；在运行中申请资源（主存储空间及外围设备因得不到满足）时，变成<u>等待资源状态</u>；进程在运行中出现了故障（程序出错或者主存储器读写错误等），变成<u>等待干预状态</u>

- 阻塞-就绪：外围设备工作结束后等待外围设备传输信息的进程结束等待；等待的资源能够得到满足时（另一个进程归还了资源），则等待资源者就结束等待；故障排除后让等待干预的进程结束等待。任何一个阻塞的进程必须先变成就绪，然后才能运行
- 运行-就绪：进程使用完时间片后强迫该进程暂时出让处理器；当有更优先权的进程要运行时也迫使正在运行的进程出让处理器。此时会变成就绪
- 就绪-运行：等待分配处理器的进程，系统按一种选定的策略从处于就绪状态的进程中选择一个进程，让他占用处理器，那个进程就变成了运行态。

##### 2.2.1.3 挂起

在另一些系统中，对于三态之外又加入了一个新的挂起状态，

原因为

- 对换的需要。缓和内存紧张的状态，<u>将内存中处于阻塞状态的进程换至外存上，使进程又处于一种有别于阻塞状态的新状态。因为即使进程所期待的事件发生（参考三态中的阻塞变就绪），但是进程仍不具备执行条件而不能进入就绪队列，这种被称为挂起。</u>
- 终端用户的请求：终端用户在自己程序运行期间，发现可疑时，往往希望自己的进程暂停，即，使正在执行进程暂停执行，若是就绪进程，则不接受调度以便研究其执行情况或对程序进行修改。这种静止状态也被称为挂起。（参考java的debug断点）
- 父进程请求：父进程希望挂起自己的子进程，以便考查和修改子进程，或者协调各子进程间的活动（参考java多线程中的出让资源？或者集合点？）
- 负荷调节的需要：当实时系统中的工作负荷较重，有可能影响对实时任务的控制时，可由系统把一些不重要的进程挂起，以保证系统正常运行（模式上比较像linux在内存满载或者CPU满载的时候会杀死一些用户进程来确保机器正常）
- 操作系统的需要：操作系统希望挂起某些进程，以便检查运行中的资源使用情况及进行记账。

属性（**静止就绪==挂起就绪， 静止阻塞==挂起阻塞**）

- 被挂起的进程，原来可能就是就绪状态，这种状态就叫**挂起就绪**。若被挂起的进程原来处于阻塞，那么这时候的状态就叫**挂起阻塞**。这种状态都不可能被调度执行
- **处于挂起阻塞状态的进程，其阻塞条件和挂起条件无关**。当进程所期待的事件出现后，进程虽不再被阻塞，但是仍然不能运行，这时，进程从静止阻塞状态转换为**挂起就绪**状态。
- 进程可以由自身挂起，也可以是用户或操作系统将其挂起。其目的都在于阻止进程继续执行，被挂起的**只能用显式方式**来激活，以便从挂起的状态解脱

![image-20220716103905270](系统架构设计师.assets/image-20220716103905270.png)

##### 2.2.1.4 进程互斥/同步

进程互斥/同步进程互斥：一组并发进程中一个或多个程序段，因共享某一共有资源而导致必须以一个不允许交叉执行的单位执行。**互斥是要保证临界资源在某一时刻只被一个进程访问**（竞争关系）

进程同步：把异步环境下的一组并发进程因**直接制约**而**互相发送消息而进行互相合作、互相等待**，使得各进程按一定的制约顺序和速度执行（协作关系）

> 系统中有些资源可供多个进程同时使用，有些只允许一个进程使用，将一次仅允许一个进程使用的资源称为**临界资源**（打印机），某些软件的变量、数据、表格也不允许两个进程同时使用（office）
>
> 把一个进程访问临界资源的那段程序代码称为**临界区**。禁止两个或两个以上的进程同时进入访问统一临界资源的临界区（类似synchronous代码块？）。

为禁止两个或两个以上的进程同时进入临界区，必须有专门的同步机构来协调，准则如下：

- 空闲让进。
- 忙则等待。
- 有限等待。有若干进程要求进入临界区时，应该在有限时间内使一进程进入临界区，即他们不应相互等待而谁也不进入临界区（用队列实现的功能？）
- 让权等待。**对于等待进入临界区的进程必须释放其占有的CPU**。信号量可以有效地实现进程的同步和互斥。在操作系统中，信号量是个整数，**当大于0时，表示可供并发进程使用的资源实体数。当小于0时表示正在使用临界区的进程数**。建立一个信号量必须说明所建信号量代表的意义和设置初值，以及建立相应的数据结构，以便指向那些正在等待使用临界区的进程。

> 对信号量只能施加特殊操作：P操作和V操作，都是原子操作，也称原语。P原语和V原语执行期间不允许中断发生。执行步骤如下
>
> 1. P操作：代码申请执行临界区时操作，先做信号量-1，如果信号量此时小于0了，进入等待（其他进程的V操作来唤醒），如果此时信号量大于0，直接进入临界区工作
>
> 2. 临界区代码：执行
>
> 3. V操作：代码执行完临界区操作，先做信号量+1， 如果信号量此时大于等于0，表示当前已经没有等待的进程了，继续执行，如果信号量小于0，表示等待队列里存在等待的进程，需要从等待队列里唤醒一等待进程，然后返回原进程继续执行或转进程调度
>
> 用PV操作实现进程同步，需要引进私用信号量，私用信号量只与制约进程和被制约进程有关，而不是整组并发进程相关。与此相对，进程互斥采用的信号量是公用信号量。首先为各并发进程设置私用信号量，然后给私用信号量赋初值，最后利用PV原语和私用信号量规定各进程的执行顺序。（同步下，P操作和V操作不一定操作单一的变量，可能与为多个，或者说甲进程执行的B变量的P操作，可能是乙进程去执行这个B变量的V操作）

##### 2.2.1.5 前趋图

一个由结点和有向边构成的有向无循环图。该图通常用于表现事务之间先后顺序的制约关系。结点可以表示一个语句，一个程序段或者一个进程，有向边表示两个结点之间存在的前趋关系。（Pert图，单（双）代号网络图都融入了前趋图的思想）

![image-20220716131928355](系统架构设计师.assets/image-20220716131928355.png)

上图可解释为，在i=（1，2，3）的情况下，取指操作为Ai， 分析操作为Bi，执行操作为Ci，对于A1来说没有前趋结点，因此被称为**开始结点**，不受制约可以执行执行，B2必须在A2和B1完成后才能开始执行，C3没有后继结点，称为**终止结点**

执行先后顺序的制约关系可以分为：

- 直接制约：**一个操作**中，**多个步骤**之间的制约关系，如A1，B1，C1就是直接制约
- 间接制约：**多个操作**中**相同步骤**的制约关系。如A1，A2，A3

##### 2.2.1.6 进程调度和死锁

进程调度即处理器调度（上下文转换）。主要功能是确定在什么时候分配处理器，并确定分给哪一个进程，即让正在执行的进程改变状态转入就绪队列的队尾，再由调度原语将就绪队列的队首进程取出投入执行。

###### 通常引起调度的原因为：

- 正在执行的进程执行完毕
- 执行进程自己调用阻塞原语将自己阻塞起来进入睡眠（类似Thread.sleep()？）
- 执行进程调用了P原语操作，从而资源不足而阻塞，或调用V原语激活了等待资源的进程队列。
- 在分时系统中，当一进程用完一个时间片
- 就绪队列中某进程的优先级变得高于当前执行进程的优先级，也将引起进程调度。

###### 进程调度的方式：

- 剥夺方式：当就绪队列中有进程的优先级高于当前执行进程的优先级时，立即发生进程调度转让处理机
- 非剥夺方式：一旦某个作业或进程占用了处理器，别的进程就不能把处理器从这个进程夺走，知道该进程因调用原语操作进入阻塞，或者时间片用完让出处理机

###### 进程调度的算法

（服务与系统目标的策略，对于不同的系统与系统目标，常采用不同的调度算法）：

- 先来先服务（FCFS）调度算法，又称先进先出（FIFO）。就绪队列按照先来后到原则排队
- 优先级调度，优先数反映了进程优先级，就绪队列按优先数排队，确定优先级的方法：
  - 静态优先级：优先级在进程开始执行前确定，执行过程中不变
  - 动态优先级：执行过程中可变
- 轮转法：就绪队列安好FCFS（FIFO）排队，每个进程执行一次占有处理器时间都不超过规定的时间单位（时间片），超过就释放自己所占有的CPU进入就绪队列末尾，等待下次调度。进程调度程序又去调度就绪队列中的第一个进程。

###### 死锁

死锁是系统的一种出错状态，不仅会浪费大量的系统资源，甚至会导致整个系统的崩溃，所以死锁应该是尽量预防和避免的

1. 死锁条件：产生死锁的主要原因是供共享的系统资源不足，资源分配策略和进程推进顺序不当。系统资源可能是可重复使用的永久性资源，也可能是消耗性的临时资源。产生死锁的必要条件是：互斥条件，保持和等待条件，不剥夺条件和环路等待条件
2. 解决死锁的策略：处于死锁状态的进程不能继续执行但又占用了系统资源，从而阻碍了其他作业的执行
   1. 死锁发生前采用预防和避免策略
   2. 死锁发生后采用检测和恢复策略。

采用的死锁预防策略通常用**资源的静态分配法或有序分配法，分别打破了资源动态分配条件和循环等待条件**，因此不会发生死锁，但是这样会大大降低系统资源的利用率和进程之间的并行程度。

死锁避免策略，**在系统进行资源分配时，先执行一个死锁避免算法**，以保证死锁不会发生，但是资源分配很频繁，因此这个也会耗费大量的CPU和时间

实际上死锁出现几率很少，因此从花的代价上看，采用检测和恢复比预防和避免代价更小一些。

#### 2.2.2 存储管理

存储器是计算机系统最重要的资源之一。任何程序和数据以及各种控制用的数据结构都必须占有一定的存储空间，因此存储管理直接影响系统性能。

外存（辅存）：软盘、硬盘、光盘等一些外部存储部件，处理器不能直接访问外存，需要通过启动I/O设备才能进行内存、外存交换，其访问速度满，但是价格便宜

内存：系统实际提供的存储单元（常指字节）组成的一个连续地址空间，处理器可以直接存取。大小由系统硬件决定，存储容量受到实际**存储单元**的限制。**虚拟存储器**（虚存）不考虑实际内存的大小和数据存储的实际地址，只考虑相关有关的数据之间的相对位置，其容量由**计算机地址的位数**决定。

系统中内存的使用一般分为，系统空间（存放操作系统本身及相关的系统程序）；用户空间（存放用户的程序和数据）

存储管理主要是对**内存储器**的管理，负责对内存的分配和回收，内存的保护和内存的扩充。存储管理的目的是提供内存的使用效率。

##### 2.2.2.1 页式存储管理

把程序的逻辑空间和内存的物理空间按照同样的大小分成若干页面，**以页面为单位进行分配**。在页式存储管理中，系统的虚地址是个有序对（页号、位移）。系统为每一个进程建立一个页表，其内容包括进程的逻辑页号和物理页号的对应关系，状态等。

动态地址转换步骤

1. 进程运行时，其页表的**首地址**已在系统的动态地址转换机构中的基本地址寄存器中
2. 执行指令访问虚存地址（p,d），根据页号p查页表，通过状态获取这个页是否调入内存，如果已经调入获得该页的内存地址p1，与页内相关位移d组合得到物理地址r，如果没有调入，则产生缺页中断，以装入所需要的页

![image-20220716142142630](系统架构设计师.assets/image-20220716142142630.png)

在装入作业时，就应在该作业的页表中指出哪些页已在内存储器中，那些没有装入内存。为了能方便地从磁盘上找到作业信息的副本，故在页表中还可指出每一页副本在磁盘上的位置。

当要装入一个当前需要的页面时，如果内存储器中无空闲块，则可选择一个已在内存储器中的页面将其调出内存。若在执行中该页面被修改过，则把该页信息重新写回到磁盘上，否则不必重新写回，当一页被暂时调出内存后，让出来的内存空间用来存放当前使用的页面。以后再使用被调出的页面时，可用同样的方法调出再装入。**页面被调出或装入之后都要对页表中的相应表目做修改**。====>**页面调度**

页面调度选择调出页面非常重要，如果采用了一个不合适的算法，就会出现，刚被调出的页面又立即要用，然后将它装入，装后不久又被选中调出，然后又被装入，如此反复调度变得非常频繁。这种现象叫做**抖动**。因此应该选择一个比较好的调度算法

- 最优算法（OPT）：选择不再使用或最远的将来才被使用的页，理想的算法很难实现，常用语淘汰算法的比较
- 随机算法（RAND）：随机地选择被淘汰的页，开销小，可能选中立即要访问的页
- 先入先出算法：选择在内存驻留时间最长的页，但可能淘汰频繁使用的页。在未给予进程分配足够的页面数时，有时会出现给予进程的页面数增多，却也此处反而增加的异常现象（在MySQL中存在优化的算法，部分先入先出）
- 最近最少使用算法（LRU）：选择离最近的一段时间内使用的最少的页。这个出发点为：某页被访问了，那可能立刻会被再次访问，相反如果长时间未被访问，那么最近也不会被访问。（Caffiene优化了这个算法）

##### 2.2.2.2 段式存储管理

与页式存储相似。分段的基本思想是把用户作业按逻辑意义上有完整意义的段来划分，并以段为单位作为内外存交换的空间尺度。

分段系统中，容许程序（作业）占据内存中许多分离的分区。每个分区存储一个程序分段。这样每个作业需要几对界限地址寄存器，判断访问地址是否越界也就更困难了。在分段存储系统中常常利用存储保护键实现存储保护。分段系统中虚地址是一个有序对（段号，位移）。系统为每个作业建立一个段表（？？？页表），其内容包括段号、段长、内存起始地址和状态等。状态指出这个段是否调入内存。

分段的动态地址转换与分页类似，如果段没调入内存会产生缺段中断。

##### 2.2.2.3 段页式存储管理

根据程序模块分段，段内在分页，内存被分划成定长的页。段页式系统中虚地址的形式是（段号，页号，页内偏移）。段页式管理采用段式分配，页式使用的方法，便于动态连接和存储的动态分配。这样存储管理能提供内存空间的利用率。

段页式存储管理为每个装入内存的作业建立一张段表，为每一段建立页表。段表指出该段的页表存放位置及长度，页表指出该段在各页在磁盘的位置以及页是否在内存中，若在内存中则填上占用的内存块号。作业时为先找段在找页，根据标识位判定不在内存中就进行页面调度

![image-20220716151548035](系统架构设计师.assets/image-20220716151548035.png)



#### 2.2.3 设备管理

##### 2.2.3.1 数据传输控制方式

设备管理的主要任务之一是控制设备和内存或CPU之间的数据传送。

选择和衡量控制方式的原则如下：

1. 数据传送速度足够高，能满足用户的需要但又不丢失数据
2. 系统开销小，所需的处理控制程序少
3. 能充分发挥硬件资源的能力，使得I/O设备尽量处于使用状态中，而CPU等待时间少。

外围设备和内存之间常用的数据传送控制方式

- 程序控制方式。处理器启动数据传输，然后等设备完成
- 中断方式。程序控制方式不能实现并发。中断方式的数据传输过程是这样的，进程启动数据传输（如读操作）后，该进程**放弃处理器**。当数据传输完成，设备控制器产生中断请求，中断处理程序对数据传输工作处理后，让相应进程成为就绪状态。以后，该进程就可以得到所需要的数据
- 直接存储访问方式（DMA）：外部设备和内存之间开辟**直接的数据交换通路**。除了控制状态寄存器和数据缓冲寄存器外，DMA控制器中还包括传输字节计数器，内存地址寄存器等。DMA方式采用**窃取处理器工作周期和控制总线**而实现辅助存储器和内存之间的数据交换。有的DMA也采用**总线浮起**方式传输大量数据。
- 通道模式：通道（输入/输出处理器，IOP），可以独立完成系统交付的输入/输出任务，通过执行自身的输入/输出专用程序进行内存和外设之间的数据传输
  - 字节多路通道
  - 选择通道
  - 成组多路通道

##### 2.2.3.2 虚设备与SPOOLING技术

采用假脱机（SPOOLING）技术，可以将低速的独占设备改造成一个可共享的设备，而且一台物理设备可以对应多台虚拟的同类设备。假脱机的意思是外部设备同时联机操作，又称为假脱机输入/输出操作，采用一组程序或进程模拟一台输入/输出处理器。**该技术利用了专门的外围控制机将低速I/O设备上的数据传送到高速设备上；再利用另一道程序来模拟脱机输出时外围控制机的功能，把高速磁盘上的数据传送到低速的I/O设备上。**

![image-20220716153818514](系统架构设计师.assets/image-20220716153818514.png)

SPOOLING系统必须有高速、大容量并且可随机存取的外存支持

> 现代计算机系统中，还可以用一台设备模拟自身，例如常见的多窗口技术，在一个终端上开多个窗口，每个窗口独立进行显示，以监视用户不同人物的执行情况。这时通过缩小显示区域平铺或重叠显示来模拟多个显示器的 

#### 2.2.4 文件管理

操作系统对计算机的管理主要为两个方面

- 硬件资源：CPU管理，存储器管理，设备管理
- 软件资源：各种系统程序，各种应用程序，各种用户程序，也包括大量的文档材料，库函数等。**每一种软件资源本身都是具有一定逻辑意义上的相关信息的集合，在操作系统中它们以文件形式存储**

文件管理的功能包括：

- 建立、修改、删除文件；

- 按文件名访问文件；决定文件信息的存放位置、存放形式、存取权限；

- 管理文件间的联系及提供对文件的共享、保护和保密等。允许多个用户协同工作又不引起混乱。文件的保护、保密实际上是用户对文件的存储权限控制问题。<u>一般存取设置两级控制：1是访问者的识别，规定哪些人可以访问；2是存取权限的识别，即有权参与访问者可对文件执行何种操作。</u>

  - 文件的共享指一个文件可以让多个用户共同使用，可以减少用户的重复劳动，节省文件的存储空间，减少输入/输出文件的次数。

  - 文件的保护主要防止由于错误操作而对文件造成的破坏

  - 文件的保密是为了防止未经授权的用户对文件进行访问。

##### 2.2.4.1 文件的逻辑结构

从用户角度所看到的文件组织形式，称为文件的逻辑结构。

逻辑结构分为

- 无结构的字符流文件
- 有结构的记录文件：由记录组成，即文件内的信息划分成多个记录，以记录单位组织和使用信息。

记录文件类型

- 顺序文件：大多数文件是顺序文件。顺序文件记录定长，记录中的数据项的类型长度与次序固定，一般还有一个可以唯一标识记录的数据项（键，Key），记录是按照键值的约定次序组织的。通常用于批处理应用，对于查询或更新某个记录的处理性能不好。
- 索引顺序文件：基于键的约定次序组织的，而且维护键的索引和溢出区域。键的索引也可以是多级索引。既适用于交互方式应用，也适用于批处理方式应用。
- 索引文件：基于记录的一个键数据项组织的。对主文件中的记录按需要的数据项（一个或几个）建索引，索引文件本身是顺序文件组织。
- 直接文件：又称hash文件，记录以它们直接访问存储设备上的物理地址直接（随机地）访问。常用语需要高速访问文件而且每次仅访问一条记录的应用中。

##### 2.2.4.2 文件的物理结构

指文件在存储设备上的存放方法。侧重于提高存储器的利用效率和降低存取时间。

文件的存储设备通常划分为大小相同的**物理块**，**物理块**是分配和传输信息的基本单位。

文件的物理结构涉及**文件存储设备的组块策略**和**文件分配策略**，决定文件信息在存储设备上的存储位置。

常用的文件分配策略：

- 顺序分配（连续分配）：文件建立时**预先分配**一组连续的物理块，然后按照逻辑文件中的信息（或记录）顺序，**依次**把信息（或）记录按顺序存储到物理块中。只需知道文件在文件存储设备上的**起始位置和文件长度**，就能进行存取。在连续存取相邻信息时，存取速度快。但是在文件建立时必须指定文件的信息长度，以后不能动态增长，**一般不适合用于经常修改的文件**。

- 链接分配（串联分配）：按单个物理块逐个进行。每个物理块中设有一个指针，指向其后续连接的下一个物理块的地址。这样形成一个**链接队列**。创建文件时可以不指定文件的长度。**说明信息中只需要指出该文件的第一个物理块号**。链接文件的文件长度可以**动态的增长**，只调整物理块指针就可以插入或删除一个信息块。优点可以解决存储器碎片问题，提高存储空间利用率。但是由于链接文件只能按照队列中的链接指针顺序查找，因此搜索效率低，**只适用于顺序访问**，**不适用于随机存取**。

- 索引分配：另一种对文件存储不连续分配的方法。采用索引分配方法的系统，为每个文件建立一张**索引表**，表中每一表项指出文件信息所在的逻辑块号和与之对应的物理块号。既可以满足文件动态增长的要求，又可以方便而迅速的实现随机存取。对一些大的文件。当索引表的大小超过一个物理块的时候，会发生索引表的分配问题。一般采用**多级（间接索引）技术**。索引表增加了存储空间的开销，存取文件时需要访问两次磁盘，一次索引表，一次访问的文件信息。可通过将操作文件前将索引表调入内存进行优化。

  ![image-20220716161803276](系统架构设计师.assets/image-20220716161803276.png)

##### 2.2.4.3 文件存储设备管理

操作系统要有效的进行存储空间的管理。由于文件存储设备是分成许多大小相同的物理块，并以块为单位交换信息，因此，文件存储设备管理实际上是对空闲块的组织和管理问题。包括空闲块的组织，空闲块的分配与空闲块的回收等问题。

空闲块管理方法：

- 索引法：**把空闲块作为文件并采用索引技术**。索引对应于一个或由多个空闲块组成的空闲区。这样磁盘上每个空闲块区都有对应索引表中的一个条目。可以有效的支持每一种文件分配方法
- 链接法：**使用链表把空闲块组织在一起**。当申请时，分配程序从链首开始摘取所需的空闲块。反之，管理程序将回收的空闲块逐个挂入队尾。适用于每一种文件分配方法。空闲块的链接方法可以按释放的先后顺序链接（<u>请求和回收空闲块的系统开销少，不利于连续空闲块的请求</u>），也可以按空闲块的大小顺序链接（<u>请求和回收空闲块的系统开销大，利于连续空闲块的请求</u>）。
- 位示图法：在外存上建立一张位示图（Bitmap），记录文件存储器的使用情况。每一位仅对应文件存储器上的一个物理块。假如系统中字长为32位（一个字能管理多少块），有4096个物理块，那么位示图的第一个字对应文件存储器上的0-31号物理块，第二个字对应32-63的物理块（二维数组）

##### 2.2.4.4 树形目录结构

在树形目录结构中，数的根结点作为根目录，数据文件作为树叶，其他所有目录都作为树的结点。

根目录在最顶层，它包含的子目录是一级子目录。以此类推，这种结构组织就叫做目录树。

在树形目录结构中，从根目录到任何数据文件之间，只有一条唯一的通路，从树根开始，把全部目录文件名与数据文件名，依次用/（Unix/Linux）或\ (Windows)连接起来。

绝对路径/相对路径

#### 2.2.5 作业管理

从用户角度看，**作业是系统为完成一个用户的计算任务所做的工作总**和。例如对于用户编制的源程序，需要经过对源程序的编译、连接编辑或连接装入及运行产生计算结果。其中的每一个步骤称为作业步。作业步顺序执行即完成了一个作业。

从系统角度看，**作业由程序、数据和作业说明书组成**。系统通过作业说明书控制文件形式的程序和数据，使之执行和操作。批处理系统中，**作业是占据内存的基本单位**。

用户的作业可以通过执行的方式，有用户自己按照作业步顺序操作（**联机方式**）

用户的作业可以通过间接的方式，由用户率先编写的作业步依次执行的说明，一次交给操作系统，由系统按照说明依次处理（**脱机方式**）

##### 2.2.5.1 作业状态及其转换

- 提交：作业由输入设备进入外存储器（输入井）称为提交状态。处于提交状态的作业，其信息正在进入系统
- 后备：作业的全部信息进入外存后，系统就为该作业建立一个作业控制块（JCB）。**系统通过JCB感知作业存在**。JCB主要包括作业名，作业状态，资源要求，作业控制方式，作业类型，作业优先权。
- 执行：一个后备作业被作业调度程序选中并分配必要资源进入内存，**作业调度程序同时为其建立了相应的进程**，该作业就由后备变为执行
- 完成：作业正常运行结束，它所占用的资源**尚未**全部被系统回收的状态为完成状态

![image-20220716165046285](系统架构设计师.assets/image-20220716165046285.png)

##### 2.2.5.2 用户接口

又称用户界面，含义

- 用户与操作系统交互的途径和通道，即操作系统的接口
  - 命令接口：键盘命令和作业控制命令
  - 程序接口：编程接口或系统调用。程序经编程接口请求系统服务，即通过系统调用程序与操作系统通信。系统调用是操作系统提供给编程人员的唯一接口。系统调用对用户屏蔽了操作系统的具体动作而只提供相关功能。系统调用大概分为设备管理，文件管理，进程控制，进程通信，存储管理等
- 这种交互环境的控制方式，即操作环境，支持命令接口和程序接口，提供友好的、易用的操作平台。命令驱动方式-菜单驱动方式、图符驱动方式和视窗操作环境。
